---
title: "Conheça Ollama e rode seu GPT localmente"
date: 2023-11-16T00:00:00.000Z
description: Como rodar modelos LLM localmente usando ollama
thumbnailUrl: /posts/thumbnail/llama.jpg
tags: ['llm', 'pt-br', 'gpt', 'ia', 'llama']
---

![Uma ilhama em um morro sem vegetação](/posts/thumbnail/llama.jpg)

Como muitos, o meu primeiro contato com LLM foi através do ChatGPT que foi criado em 2022 e se popularizou nos meses seguintes. Como todo o trabalho de uma
IA generativa, são necessários alguns processos para que ela se torne usável como o caso do ChatGPT.

## Processos

Em todo o processo de construção de um IA Generativa é necessário o trabalho humano como a produção de dados, organização e desenvolvimento de ferramentas para
coleta e armazenamento de dados gerados por pessoas. Também é necessário que, após a coleta desses dados, uma seleção de dados sejam feita para treinamento e outra seleção seja feita durante ou após o treinamento desses dados, que no final será chamado de modelo.

## Modelo

O modelo gerado por um treinamento é apenas o resultado de trabalho humano que usa uma quantidade muito grande de informações no processo, dessa forma podem ter inúmeros problemas de vieses na coleta, seleção e filtragem de dados que os dados foram submetidos para o modelo ser gerado.

## LLM

Com tudo isso em mente podemos começar a discussão sobre LLM, que é um Large Language Models, ou, em português, Modelos de Linguagem Grande, ou seja um modelo gerado com uma grande quantidade de dados e especializado em interagir com humanos através de textos. Como se espera em todo o processo desde a concepção até a execução de um modelo LLM o alto consumo de recursos computacionais é bem importante, o que inviabiliza a construção e até a execução de modelos através de computadores menos potentes. Isso era uma verdade, porém, com a evolução e altos investimentos que a popularidade do ChatGPT trouxe para essa areá, sugiram novos mecanismos que tentam diminuir o uso de recursos, ao menos para a execução de modelos LLM, como o caso do [llama](https://ai.meta.com/llama/) que foi feito pela equipe de pesquisa do Facebook (Meta) que tornou o modelo open source e com um requisito menor de recurso computacional para roda lo.

## Ollama

Como o modelo llama foi disponibilizado open source muitos desenvolvedores criaram formas de facilitar o uso deles por outras pessoas e com esse intuito nasceu o projeto Ollama que facilita baixar e rodar modelos LLM localmente.

## Seu GPT localmente

Para rodar seu GPT localmente é necessário ter em mente alguns requisitos que cada modelo necessita, como:

- 7b de parâmetros  -> 8GB de RAM
- 13b de parâmetros -> 16GB de RAM

Todos os modelos de LLM rodam com números consideráveis de parâmetros, geralmente o minimo é 7b que é 7 bilhões de parâmetros.

Considerando que você tenha os recursos necessários para rodar o modelo que você deseja, é necessário, baixar o binário do Ollama pelo site: https://ollama.ai/ Escolher o modelo disponível e rodar na linha de comando.

> ollama run llama2

## Usando versão web/desktop

Como o projeto Ollama nasceu para facilitar o acesso aos modelos LLMs então é possível fazer uso do mesmo através de REST API. Dito isso, você pode construir sua versão usando a API do ollama ou usar algum projeto da [construído pela comunidade](https://github.com/jmorganca/ollama#web--desktop).

## Considerações

- Embora hoje o requisito minimo para rodar um modelo llm seja bem menor, ainda não é acessível para a maioria das pessoas.
- Os modelos apresentados no site do Ollama são construidos por diferentes pessoas por diferentes processos o que podem ter diversos problemas, como a dificuldade de responder em outras línguas diferente do inglês.
- Como esse tema apesar de parecer novo já existe muito trabalho que deram base para a popularização que tem hoje, permite que uma pessoa com pouco conhecimento na área como eu possa usar e escrever sobre esse tema. Caso tenha algum erro no texto sinta se livre para corrigi-lo acessando o código do texto no repositório no GitHub.
- Apesar de muitos trabalhos relacionado a construção de modelos de IA começarem a décadas, as discussões éticas e problemas nesses modelos ainda estão começando a ganhar notoriedade, então fique atento a possíveis problemas nos modelos desde a concepção a aplicação do mesmo, não da para criar um modelo sem viés.
